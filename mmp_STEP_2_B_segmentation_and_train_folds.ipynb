{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2 B: From categorical to One-Hot Vector and Segmentation and fold training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From categorical to One-Hot Vector dataset and segmentations of the different training \"folds\". In the section, we will compute the fold training instead of exporting the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.trainFoldB import train_test, saveColumnsToPartition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/train_cleaned.csv', index_col='MachineIdentifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_categorical = df.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Threshold of the size of different values of each categorical data\n",
    "h_threshold = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "columns_to_partition = []\n",
    "columns_to_onehot = []\n",
    "for c in columns_categorical:\n",
    "    values = df[c].nunique()\n",
    "    suf = \"\"\n",
    "    if (values > h_threshold):\n",
    "        columns_to_partition.append(c)\n",
    "        suf = ', PARTITION'\n",
    "    else:\n",
    "        columns_to_onehot.append(c)\n",
    "    total += values\n",
    "    print(c,': ',values,suf)\n",
    "print('Total new vars: ' + str(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation and train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to split the dataset based on the most scattered categorical variables  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "asvGB = df.groupby(columns_to_partition)['ProductName'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ... Maybe it is not a good idea to order this this way\n",
    "#asvGB.sort_values(ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "asvGBdf=asvGB.to_frame()\n",
    "asvGBdf.columns=['count']\n",
    "asvGBdf.sort_index(level=[0,1,2],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(asvGBdf['count'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, let's select indicators for each group and create a dictionary. Each group will have 200.000 elements aprox:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NE = 364000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "asvGBDict = asvGBdf.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = 0\n",
    "f=1 # fold\n",
    "\n",
    "foldDict = {}\n",
    "for key, value in asvGBDict['count'].items():\n",
    "    acc += value\n",
    "    if (acc > NE):\n",
    "        acc = 0\n",
    "        f += 1\n",
    "    foldDict[key]=f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setFold(row):\n",
    "    real_row = row.values\n",
    "    return foldDict[(real_row[0],real_row[1],real_row[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['fold'] = df[columns_to_partition].apply(axis=1, func=setFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x='fold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all this folds to train, let's  get the different files with 50% of data to train the ensembled block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nFolds = df['fold'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "lcurves = []\n",
    "for i in range(nFolds):\n",
    "    print('processing fold ',(i+1),' ... ')\n",
    "    fold_df = df[df['fold']==(i+1)]\n",
    "    columns_categorical = fold_df.select_dtypes(include=['object']).columns\n",
    "    fold_df_num=pd.get_dummies(data=fold_df,columns=columns_categorical)    \n",
    "    m=fold_df.shape[0]\n",
    "    tm = int(m/2)\n",
    "    ensemble_df = fold_df_num[0:tm]\n",
    "    stack_df = fold_df[tm:]\n",
    "\n",
    "    # Save columns to partition values\n",
    "    saveColumnsToPartition(i+1, fold_df, columns_to_partition)\n",
    "    \n",
    "    # ensemble process\n",
    "    ensemble_df.drop(labels=['fold'],axis=1,inplace=True)\n",
    "    (score, lcurve) = train_test(i+1,ensemble_df)\n",
    "    scores.append(score)\n",
    "    lcurves.append(lcurve)\n",
    "    \n",
    "    # stacking process\n",
    "    if (i == 0):\n",
    "        stack_complete_df = stack_df.copy()\n",
    "    else:\n",
    "        stack_complete_df = pd.concat([stack_complete_df, stack_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_complete_df.to_csv('datasets/train_stack.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the results of the training of each fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showFoldModelInfo(fold_id):\n",
    "    print('scoring: ',str(scores[i-1]))\n",
    "    plt.plot(lcurves[i-1][0,:],'b',lcurves[i-1][1,:],'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "showFoldModelInfo(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "showFoldModelInfo(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "showFoldModelInfo(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "showFoldModelInfo(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "showFoldModelInfo(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "showFoldModelInfo(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "showFoldModelInfo(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "showFoldModelInfo(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "showFoldModelInfo(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# End of Analisys! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this execution we have the \"folded\" models and the \"stacking\" dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
